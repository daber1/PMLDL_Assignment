{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23b05dd5",
   "metadata": {},
   "source": [
    "## Downloading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bcea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4213bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://github.com/skoltech-nlp/detox/releases/download/emnlp2021/filtered_paranmt.zip\"\n",
    "r = requests.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bda70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f02616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " '1.0-initial-data-exploration.ipynb',\n",
       " '2.0-data-preprocessing.ipynb',\n",
       " 'filtered.tsv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400e824",
   "metadata": {},
   "source": [
    "## Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b3e998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13cbc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('filtered.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ada2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that it has extra column (the first one) that we need to remove\n",
    "data.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7a152",
   "metadata": {},
   "source": [
    "|Column name     |   Description |\n",
    "| --- | --------- |\n",
    "| reference|           original text|\n",
    "|translation|         modified text(less toxic)|\n",
    "|similarity|          cosine similarity of text(how similar they are)|\n",
    "|lenght_diff|         relative length difference($\\frac{\\text{translation}-\\text{ref}}{\\text{ref}}$)|\n",
    "| ref_tox|toxicity of reference|\n",
    "|trn_tox|toxicifiy of translation|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bc0ca",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b16cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reference  \\\n",
       "0  If Alkar is flooding her with psychic waste, t...   \n",
       "1                          Now you're getting nasty.   \n",
       "2           Well, we could spare your life, for one.   \n",
       "3          Ah! Monkey, you've got to snap out of it.   \n",
       "4                   I've got orders to put her down.   \n",
       "\n",
       "                                         translation  similarity  lenght_diff  \\\n",
       "0  if Alkar floods her with her mental waste, it ...    0.785171     0.010309   \n",
       "1                        you're becoming disgusting.    0.749687     0.071429   \n",
       "2                      well, we can spare your life.    0.919051     0.268293   \n",
       "3                       monkey, you have to wake up.    0.664333     0.309524   \n",
       "4                         I have orders to kill her.    0.726639     0.181818   \n",
       "\n",
       "    ref_tox   trn_tox  \n",
       "0  0.014195  0.981983  \n",
       "1  0.065473  0.999039  \n",
       "2  0.213313  0.985068  \n",
       "3  0.053362  0.994215  \n",
       "4  0.009402  0.999348  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd0929a",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8b0aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def lower_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_numbers(text):\n",
    "    text_nonum = re.sub(r'\\d+', ' ', text)\n",
    "    return text_nonum\n",
    "\n",
    "def remove_punc(text):\n",
    "    text_nopunc = re.sub(r'[^a-z|\\s]', ' ', text)\n",
    "    return text_nopunc\n",
    "\n",
    "def remove_multi_spaces(text):\n",
    "    text_no_doublespaces = re.sub('\\s+', ' ', text).strip()\n",
    "    return text_no_doublespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc9bae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: 'I swear to God, the best thing I ever did in my life was save that little son of a bitch'\n",
      "Clean text: 'i swear to god the best thing i ever did in my life was save that little son of a bitch'\n"
     ]
    }
   ],
   "source": [
    "sample_text = data.reference[43]\n",
    "print(f\"Original text: \\'{sample_text}\\'\")\n",
    "clean_text = remove_multi_spaces(remove_punc(remove_numbers(lower_text(sample_text))))\n",
    "print(f\"Clean text: \\'{clean_text}\\'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63ba59",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fca2f126",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vlad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stop_words(tokens):\n",
    "    return [w for w in tokens if w not in stop_words]\n",
    "\n",
    "def stem_words(tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [stemmer.stem(word) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58912557",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = stem_words(remove_stop_words(tokenize_text(clean_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "28553942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swear',\n",
       " 'god',\n",
       " 'best',\n",
       " 'thing',\n",
       " 'ever',\n",
       " 'life',\n",
       " 'save',\n",
       " 'littl',\n",
       " 'son',\n",
       " 'bitch']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6be9f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    _lowered = lower_text(text)\n",
    "    _without_numbers = remove_numbers(_lowered)\n",
    "    _without_punct = remove_punc(_without_numbers)\n",
    "    _single_spaced = remove_multi_spaces(_without_punct)\n",
    "    _tokenized = tokenize_text(_single_spaced)\n",
    "    _without_sw = remove_stop_words(_tokenized)\n",
    "    _stemmed = stem_words(_without_sw)\n",
    "    \n",
    "    return _stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8bd78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reference'] = data['reference'].apply(preprocess)\n",
    "data['translation'] = data['translation'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4959d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
